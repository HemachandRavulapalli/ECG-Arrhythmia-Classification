# backend/src/data_loader.py
import os
import numpy as np
import pandas as pd
import wfdb
from sklearn.preprocessing import LabelEncoder, OneHotEncoder

# -----------------------------
# Base paths
# -----------------------------
BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), "../.."))
RAW_DIR = os.path.join(BASE_DIR, "data", "raw")
PROCESSED_DIR = os.path.join(BASE_DIR, "data", "processed")
KARDIA_DIR = os.path.join(BASE_DIR, "data", "kardia")

# -----------------------------
# Unified target classes
# -----------------------------
TARGET_CLASSES = [
    "Normal Sinus Rhythm",
    "Atrial Fibrillation",
    "Bradycardia",
    "Tachycardia",
    "Ventricular Arrhythmias",
]

# -----------------------------
# Utility
# -----------------------------
def segment_signal(signal, window_size=1000, step=1000):
    segments = []
    for start in range(0, len(signal) - window_size + 1, step):
        segments.append(signal[start:start + window_size])
    return np.array(segments)

# -----------------------------
# Label map
# -----------------------------
LABEL_MAP = {
    # MIT-BIH
    "N": "Normal Sinus Rhythm",
    "L": "Normal Sinus Rhythm",
    "R": "Normal Sinus Rhythm",
    "A": "Atrial Fibrillation",
    "a": "Atrial Fibrillation",
    "S": "Tachycardia",
    "F": "Ventricular Arrhythmias",
    "V": "Ventricular Arrhythmias",
    "B": "Bradycardia",

    # PTB-XL
    "NORM": "Normal Sinus Rhythm",
    "SR": "Normal Sinus Rhythm",
    "SBRAD": "Bradycardia",
    "STACH": "Tachycardia",
    "AFIB": "Atrial Fibrillation",
    "VEB": "Ventricular Arrhythmias",
    "VT": "Ventricular Arrhythmias",
}

def map_label_to_target(lbl):
    if lbl is None:
        return None
    s = str(lbl).strip()
    if s in TARGET_CLASSES:
        return s
    if s in LABEL_MAP:
        return LABEL_MAP[s]
    su = s.upper()
    if su in LABEL_MAP:
        return LABEL_MAP[su]
    sl = s.lower()
    for k, v in LABEL_MAP.items():
        if k.lower() == sl:
            return v
    if "atrial" in s.lower() and "fibril" in s.lower():
        return "Atrial Fibrillation"
    if "brady" in s.lower():
        return "Bradycardia"
    if "tachy" in s.lower():
        return "Tachycardia"
    if "ventr" in s.lower() or "vt" in s.lower():
        return "Ventricular Arrhythmias"
    if "sinus" in s.lower() and "normal" in s.lower():
        return "Normal Sinus Rhythm"
    return None

# -----------------------------
# MIT-BIH loader
# -----------------------------
def load_mitdb(limit=None, window_size=1000):
    mit_dir = os.path.join(RAW_DIR, "mitdb")
    ann_file = os.path.join(RAW_DIR, "mitdb_annotations.csv")
    if not os.path.exists(ann_file):
        print("‚ö†Ô∏è MIT-BIH annotations not found, skipping.")
        return np.empty((0, window_size)), np.array([])

    df = pd.read_csv(ann_file)
    signals, labels = [], []
    for _, row in df.iterrows():
        record_path = os.path.join(mit_dir, str(row["record"]))
        try:
            sig, _ = wfdb.rdsamp(record_path)
        except:
            continue
        sig = sig[:, 0] if sig.ndim > 1 else sig
        segs = segment_signal(sig, window_size)
        mapped = map_label_to_target(row.get("label") or row.get("annotation"))
        if mapped:
            signals.extend(segs)
            labels.extend([mapped] * len(segs))
        if limit and len(signals) >= limit:
            break
    return np.array(signals), np.array(labels)

# -----------------------------
# MIT-BIH Ventricular Arrhythmias loader (example, adjust paths/annotations)
# -----------------------------
def load_mitdb_veb(limit=None, window_size=1000):
    """Load Ventricular Arrhythmias data from MIT-BIH annotations or create synthetic data"""
    ann_file = os.path.join(RAW_DIR, "mitdb_annotations.csv")
    
    if not os.path.exists(ann_file):
        print("üì• MIT-BIH annotations not found, creating synthetic Ventricular Arrhythmias data...")
        return create_synthetic_ventricular_data(limit, window_size)
    
    print("üì• Loading Ventricular Arrhythmias from MIT-BIH annotations...")
    df = pd.read_csv(ann_file)
    
    # Filter for ventricular arrhythmias (V, F codes)
    veb_codes = ['V', 'F', 'VE', 'VEB', 'VT']
    veb_records = df[df['label'].isin(veb_codes)]
    
    if len(veb_records) == 0:
        print("üì• No ventricular arrhythmias found in MIT-BIH, creating synthetic data...")
        return create_synthetic_ventricular_data(limit, window_size)
    
    signals, labels = [], []
    mitdb_dir = os.path.join(RAW_DIR, "mitdb")
    
    for _, row in veb_records.iterrows():
        record_name = str(row['record'])
        record_path = os.path.join(mitdb_dir, record_name)
        
        try:
            sig, _ = wfdb.rdsamp(record_path)
            sig = sig[:, 0] if sig.ndim > 1 else sig
            segs = segment_signal(sig, window_size)
            signals.extend(segs)
            labels.extend(["Ventricular Arrhythmias"] * len(segs))
            if limit and len(signals) >= limit:
                break
        except Exception as e:
            print(f"‚ö†Ô∏è Error loading record {record_name}: {e}")
            continue
    
    if len(signals) == 0:
        print("üì• No valid ventricular arrhythmias loaded, creating synthetic data...")
        return create_synthetic_ventricular_data(limit, window_size)
    
    print(f"‚úÖ Loaded {len(signals)} Ventricular Arrhythmias samples")
    return np.array(signals), np.array(labels)

def create_synthetic_ventricular_data(limit=None, window_size=1000):
    """Create synthetic Ventricular Arrhythmias data based on characteristic patterns"""
    print("üîß Creating synthetic Ventricular Arrhythmias data...")
    
    # Generate synthetic ventricular arrhythmias with irregular patterns
    n_samples = limit if limit else 1000
    signals, labels = [], []
    
    for i in range(n_samples):
        # Create irregular rhythm with premature ventricular contractions
        t = np.linspace(0, 4, window_size)  # 4 seconds at 250 Hz
        
        # Base sinus rhythm
        base_freq = 0.8 + np.random.normal(0, 0.1)  # Hz
        signal = np.sin(2 * np.pi * base_freq * t)
        
        # Add premature ventricular contractions (PVCs)
        n_pvcs = np.random.randint(2, 8)
        for _ in range(n_pvcs):
            pvc_time = np.random.uniform(0.5, 3.5)
            pvc_idx = int(pvc_time * window_size / 4)
            if pvc_idx < window_size - 50:
                # Create PVC pattern - wide, bizarre QRS
                pvc_duration = np.random.randint(20, 40)
                pvc_amplitude = np.random.uniform(1.5, 3.0)
                pvc_signal = pvc_amplitude * np.exp(-((np.arange(pvc_duration) - pvc_duration/2) / (pvc_duration/4))**2)
                
                # Add to signal
                end_idx = min(pvc_idx + pvc_duration, window_size)
                actual_duration = end_idx - pvc_idx
                signal[pvc_idx:end_idx] += pvc_signal[:actual_duration]
        
        # Add noise
        noise = np.random.normal(0, 0.1, window_size)
        signal += noise
        
        # Normalize
        signal = (signal - np.mean(signal)) / np.std(signal)
        
        signals.append(signal)
        labels.append("Ventricular Arrhythmias")
    
    print(f"‚úÖ Created {len(signals)} synthetic Ventricular Arrhythmias samples")
    return np.array(signals), np.array(labels)

def create_synthetic_kardia_data(limit=None, window_size=1000):
    """Create synthetic Kardia data with balanced class distribution"""
    print("üîß Creating synthetic Kardia data...")
    
    # Generate balanced synthetic data for all 5 classes
    signals, labels = [], []
    samples_per_class = (limit // 5) if limit else 200
    
    for class_name in TARGET_CLASSES:
        for _ in range(samples_per_class):
            # Generate synthetic ECG signal based on class characteristics
            if class_name == "Normal Sinus Rhythm":
                # Regular sinus rhythm
                t = np.linspace(0, 1, window_size)
                signal = np.sin(2 * np.pi * 72 * t) + 0.1 * np.random.randn(window_size)
            elif class_name == "Atrial Fibrillation":
                # Irregular rhythm with fibrillatory waves
                t = np.linspace(0, 1, window_size)
                signal = np.sin(2 * np.pi * 100 * t + np.random.randn() * 0.5) + 0.2 * np.random.randn(window_size)
            elif class_name == "Bradycardia":
                # Slow rhythm
                t = np.linspace(0, 1, window_size)
                signal = np.sin(2 * np.pi * 45 * t) + 0.1 * np.random.randn(window_size)
            elif class_name == "Tachycardia":
                # Fast rhythm
                t = np.linspace(0, 1, window_size)
                signal = np.sin(2 * np.pi * 120 * t) + 0.1 * np.random.randn(window_size)
            elif class_name == "Ventricular Arrhythmias":
                # Irregular ventricular rhythm
                t = np.linspace(0, 1, window_size)
                signal = np.sin(2 * np.pi * 80 * t + np.random.randn() * 0.3) + 0.15 * np.random.randn(window_size)
            
            # Normalize
            signal = (signal - np.mean(signal)) / np.std(signal)
            
            signals.append(signal)
            labels.append(class_name)
    
    print(f"‚úÖ Created {len(signals)} synthetic Kardia samples")
    return np.array(signals), np.array(labels)

def create_synthetic_ptbxl_data(limit=None, window_size=1000):
    """Create synthetic PTB-XL data with balanced class distribution"""
    print("üîß Creating synthetic PTB-XL data...")
    
    # Generate balanced synthetic data for all 5 classes
    signals, labels = [], []
    samples_per_class = (limit // 10) if limit else 100  # Split between train/test
    
    for class_name in TARGET_CLASSES:
        for _ in range(samples_per_class):
            # Generate synthetic ECG signal based on class characteristics
            if class_name == "Normal Sinus Rhythm":
                # Regular sinus rhythm
                t = np.linspace(0, 1, window_size)
                signal = np.sin(2 * np.pi * 72 * t) + 0.1 * np.random.randn(window_size)
            elif class_name == "Atrial Fibrillation":
                # Irregular rhythm with fibrillatory waves
                t = np.linspace(0, 1, window_size)
                signal = np.sin(2 * np.pi * 100 * t + np.random.randn() * 0.5) + 0.2 * np.random.randn(window_size)
            elif class_name == "Bradycardia":
                # Slow rhythm
                t = np.linspace(0, 1, window_size)
                signal = np.sin(2 * np.pi * 45 * t) + 0.1 * np.random.randn(window_size)
            elif class_name == "Tachycardia":
                # Fast rhythm
                t = np.linspace(0, 1, window_size)
                signal = np.sin(2 * np.pi * 120 * t) + 0.1 * np.random.randn(window_size)
            elif class_name == "Ventricular Arrhythmias":
                # Irregular ventricular rhythm
                t = np.linspace(0, 1, window_size)
                signal = np.sin(2 * np.pi * 80 * t + np.random.randn() * 0.3) + 0.15 * np.random.randn(window_size)
            
            # Normalize
            signal = (signal - np.mean(signal)) / np.std(signal)
            
            signals.append(signal)
            labels.append(class_name)
    
    # Split into train/test (80/20)
    split_idx = int(len(signals) * 0.8)
    train_signals = signals[:split_idx]
    train_labels = labels[:split_idx]
    test_signals = signals[split_idx:]
    test_labels = labels[split_idx:]
    
    print(f"‚úÖ Created {len(train_signals)} train and {len(test_signals)} test synthetic PTB-XL samples")
    return (np.array(train_signals), np.array(train_labels)), (np.array(test_signals), np.array(test_labels))

def create_synthetic_missing_classes(missing_classes, limit=None, window_size=1000):
    """Create synthetic data for missing classes to ensure all 5 classes are present"""
    print(f"üîß Creating synthetic data for missing classes: {missing_classes}")
    
    signals, labels = [], []
    samples_per_class = (limit // 10) if limit else 50  # Small number to fill gaps
    
    for class_name in missing_classes:
        for _ in range(samples_per_class):
            # Generate synthetic ECG signal based on class characteristics
            if class_name == "Normal Sinus Rhythm":
                # Regular sinus rhythm
                t = np.linspace(0, 1, window_size)
                signal = np.sin(2 * np.pi * 72 * t) + 0.1 * np.random.randn(window_size)
            elif class_name == "Atrial Fibrillation":
                # Irregular rhythm with fibrillatory waves
                t = np.linspace(0, 1, window_size)
                signal = np.sin(2 * np.pi * 100 * t + np.random.randn() * 0.5) + 0.2 * np.random.randn(window_size)
            elif class_name == "Bradycardia":
                # Slow rhythm
                t = np.linspace(0, 1, window_size)
                signal = np.sin(2 * np.pi * 45 * t) + 0.1 * np.random.randn(window_size)
            elif class_name == "Tachycardia":
                # Fast rhythm
                t = np.linspace(0, 1, window_size)
                signal = np.sin(2 * np.pi * 120 * t) + 0.1 * np.random.randn(window_size)
            elif class_name == "Ventricular Arrhythmias":
                # Irregular ventricular rhythm
                t = np.linspace(0, 1, window_size)
                signal = np.sin(2 * np.pi * 80 * t + np.random.randn() * 0.3) + 0.15 * np.random.randn(window_size)
            
            # Normalize
            signal = (signal - np.mean(signal)) / np.std(signal)
            
            signals.append(signal)
            labels.append(class_name)
    
    print(f"‚úÖ Created {len(signals)} synthetic samples for missing classes")
    return np.array(signals), np.array(labels)

# -----------------------------
# PTB-XL loader (patient-safe)
# -----------------------------
def load_ptbxl(limit=None, window_size=1000):
    ann_file = os.path.join(RAW_DIR, "ptbxl", "ptbxl_database.csv")
    scp_file = os.path.join(RAW_DIR, "ptbxl", "scp_statements.csv")
    if not os.path.exists(ann_file):
        print("üì• PTB-XL annotations not found, creating synthetic data...")
        return create_synthetic_ptbxl_data(limit, window_size)

    df = pd.read_csv(ann_file)
    scp_df = pd.read_csv(scp_file, index_col=0)
    scp_df = scp_df[scp_df.diagnostic == 1]

    def map_superclass(scp_codes):
        try:
            codes = eval(scp_codes) if isinstance(scp_codes, str) else scp_codes
        except Exception:
            return None
        found = []
        for code in codes.keys():
            if code in LABEL_MAP:
                found.append(LABEL_MAP[code])
        if not found:
            return None
        priority = [
            "Atrial Fibrillation",
            "Ventricular Arrhythmias",
            "Tachycardia",
            "Bradycardia",
            "Normal Sinus Rhythm",
        ]
        for p in priority:
            if p in found:
                return p
        return found[0]

    df["mapped"] = df["scp_codes"].apply(map_superclass)
    df = df.dropna(subset=["mapped"])

    train_df = df[df.strat_fold < 9]
    test_df = df[df.strat_fold == 10]

    def load_rows(sub_df):
        X, y = [], []
        for _, row in sub_df.iterrows():
            npz_path = os.path.join(PROCESSED_DIR, "ptbxl", f"{row['ecg_id']}.npz")
            if not os.path.exists(npz_path):
                continue
            try:
                data = np.load(npz_path)
                sig = data["signal"][:window_size]
                if sig.shape[0] < window_size:
                    sig = np.pad(sig, (0, window_size - len(sig)))
                X.append(sig)
                y.append(row["mapped"])
                if limit and len(X) >= limit:
                    break
            except Exception:
                continue
        return np.array(X), np.array(y)

    return load_rows(train_df), load_rows(test_df)

# -----------------------------
# Kardia loader
# -----------------------------
def load_kardia(folder_path, window_size=1000):
    # Try multiple possible locations for Kardia data
    possible_paths = [
        (os.path.join(folder_path, "X.npy"), os.path.join(folder_path, "Y.npy")),
        (os.path.join(BASE_DIR, "data", "X.npy"), os.path.join(BASE_DIR, "data", "Y.npy")),
        (os.path.join(BASE_DIR, "data", "X.npy"), os.path.join(BASE_DIR, "data", "y.npy")),
    ]
    
    X_path, y_path = None, None
    for x_p, y_p in possible_paths:
        if os.path.exists(x_p) and os.path.exists(y_p):
            X_path, y_path = x_p, y_p
            break
    
    if not (X_path and y_path):
        print("üì• Kardia data not found in expected locations, creating synthetic data...")
        return create_synthetic_kardia_data(limit, window_size)

    print(f"üì• Loading Kardia data from: {X_path}, {y_path}")
    X = np.load(X_path, allow_pickle=True)
    y_raw = np.load(y_path, allow_pickle=True)

    X_fixed, y_fixed = [], []
    for sig, lbl in zip(X, y_raw):
        # Handle the data format - X is (15, 1) with single values, Y is (15,) with strings
        if isinstance(sig, np.ndarray) and sig.shape == (1,):
            sig = sig[0]  # Extract the single value
        elif isinstance(sig, np.ndarray) and len(sig) == 1:
            sig = sig[0]
        
        # Convert to proper types
        try:
            sig = float(sig)  # Single value
            lbl = str(lbl)
        except:
            continue
            
        # Create a synthetic signal from the single value
        # This is a placeholder - in real implementation, you'd want actual ECG data
        if sig != 0:  # Skip zero values
            # Create a simple synthetic ECG-like signal
            t = np.linspace(0, 4, window_size)  # 4 seconds
            synthetic_sig = sig * np.sin(2 * np.pi * 1.2 * t) + 0.1 * np.random.randn(window_size)
            synthetic_sig = (synthetic_sig - np.mean(synthetic_sig)) / np.std(synthetic_sig)
            
            mapped = map_label_to_target(lbl)
            if mapped:
                X_fixed.append(synthetic_sig)
                y_fixed.append(mapped)
    
    print(f"‚úÖ Loaded {len(X_fixed)} Kardia samples with {len(set(y_fixed))} unique classes: {set(y_fixed)}")
    return np.array(X_fixed), np.array(y_fixed)

# -----------------------------
# Duplicate check utility
# -----------------------------
def check_duplicates(X, name="Dataset"):
    unique_rows = np.unique(X, axis=0)
    if len(unique_rows) < len(X):
        print(f"‚ö†Ô∏è Warning: {name} contains {len(X) - len(unique_rows)} duplicate samples.")
    else:
        print(f"{name} contains no duplicates.")

# -----------------------------
# Combined loader with VEB included and no leakage
# -----------------------------
def load_all_datasets(limit=None, one_hot=True, window_size=1000):
    print("üì• Loading PTB-XL...")
    (X_ptb_train, y_ptb_train), (X_ptb_test, y_ptb_test) = load_ptbxl(limit, window_size)
    print(f"‚úÖ PTB-XL: Train={X_ptb_train.shape}, Test={X_ptb_test.shape}")

    print("üì• Loading MIT-BIH...")
    X_mit, y_mit = load_mitdb(limit, window_size)
    print(f"‚úÖ MIT-BIH: {X_mit.shape}")

    print("üì• Loading MIT-BIH VEB...")
    X_veb, y_veb = load_mitdb_veb(limit, window_size)
    print(f"‚úÖ MIT-BIH VEB: {X_veb.shape}")

    print("üì• Loading Kardia...")
    X_kardia, y_kardia = load_kardia(KARDIA_DIR, window_size)
    print(f"‚úÖ Kardia: {X_kardia.shape}")

    # Training set combines PTB-XL train + MIT-BIH + MIT-BIH VEB + Kardia
    # Ensure all arrays have the same number of dimensions
    datasets = [(X_ptb_train, y_ptb_train), (X_mit, y_mit), (X_veb, y_veb), (X_kardia, y_kardia)]
    X_train_parts, y_train_parts = [], []
    
    for X_part, y_part in datasets:
        if len(X_part) > 0:
            # Ensure X_part is 2D
            if X_part.ndim == 1:
                X_part = X_part.reshape(-1, 1)
            elif X_part.ndim == 3:
                X_part = X_part.reshape(X_part.shape[0], -1)
            X_train_parts.append(X_part)
            y_train_parts.append(y_part)
    
    if X_train_parts:
        X_train = np.concatenate(X_train_parts)
        y_train = np.concatenate(y_train_parts)
    else:
        X_train = np.empty((0, window_size))
        y_train = np.array([])

    # Test set is PTB-XL test fold
    X_test = X_ptb_test
    y_test = y_ptb_test

    # Clean labels to target classes only
    y_train = np.array([lbl for lbl in y_train if lbl in TARGET_CLASSES])
    y_test = np.array([lbl for lbl in y_test if lbl in TARGET_CLASSES])
    X_train = X_train[:len(y_train)]
    X_test = X_test[:len(y_test)]

    # Get unique classes actually present in the data
    unique_classes = sorted(list(set(y_train) | set(y_test)))
    print(f"üìä Found {len(unique_classes)} unique classes in data: {unique_classes}")
    
    # Ensure we have all 5 classes by adding synthetic data for missing classes
    missing_classes = set(TARGET_CLASSES) - set(unique_classes)
    if missing_classes:
        print(f"üì• Adding synthetic data for missing classes: {missing_classes}")
        X_synthetic, y_synthetic = create_synthetic_missing_classes(missing_classes, limit, window_size)
        X_train = np.concatenate([X_train, X_synthetic])
        y_train = np.concatenate([y_train, y_synthetic])
        unique_classes = TARGET_CLASSES
        print(f"‚úÖ Now have all 5 classes: {unique_classes}")
    
    # Always use all 5 target classes for encoding
    le = LabelEncoder()
    le.fit(TARGET_CLASSES)
    y_train_int = np.array([le.transform([lbl])[0] for lbl in y_train])
    y_test_int = np.array([le.transform([lbl])[0] for lbl in y_test])

    if one_hot:
        ohe = OneHotEncoder(sparse_output=False)
        # Always use 5 classes for one-hot encoding
        ohe.fit(np.arange(5).reshape(-1, 1))
        y_train_enc = ohe.transform(y_train_int.reshape(-1, 1))
        y_test_enc = ohe.transform(y_test_int.reshape(-1, 1))
    else:
        y_train_enc, y_test_enc = y_train_int, y_test_int

    print(f"üìä Combined dataset: Train={X_train.shape}, Test={X_test.shape}, Classes={list(le.classes_)}")

    # Duplication check example
    check_duplicates(X_train, "Training set")
    check_duplicates(X_test, "Test set")

    # Always return 5 classes for consistent model architecture
    return (X_train, y_train_enc), (X_test, y_test_enc), TARGET_CLASSES
